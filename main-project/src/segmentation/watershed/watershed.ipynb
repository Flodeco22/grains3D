{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seeded watershed segmentation\n",
    "This program uses seeded watershed for grain segmentation.\n",
    "\n",
    "It takes two input images : a background image to segment and a label image.\\\n",
    "The label image needs to have a pure black background for the program to work.\n",
    "\n",
    "Explanation of the algorithm : https://youtu.be/LT8L3vSLQ2Q?t=2124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "- argparse : to manage command line arguments.\n",
    "- os : for manipulating file paths.\n",
    "- tifffile : for reading and writing TIFF files.\n",
    "- numpy (alias np) : for manipulating numerical vectors.\n",
    "- timeit for timer() : to measure execution time.\n",
    "- hg : an image processing library (a hierarchical processing library).\n",
    "- skimage : an image processing library (a lot of sub-library to import).\n",
    "\n",
    "#### French\n",
    "\n",
    "- argparse : pour gérer les arguments de la ligne de commande.\n",
    "- os : pour manipuler les chemins de fichiers.\n",
    "- tifffile : pour lire et écrire des fichiers TIFF.\n",
    "- numpy (alias np) : pour manipuler les tableaux numériques.\n",
    "- timeit pour le timer() : pour mesurer le temps d'exécution.\n",
    "- hg : une bibliothèque de traitement d'images (une bibliothèque de traitement par hiérarchies).\n",
    "- skimage : une librairie de traitement d'images (énormément de sous-bibliothèques à importer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Lysandre Macke\"\n",
    "# Adapted by Jonathan Palisse\n",
    "__contact__ = \"lmacke@unistra.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import higra as hg # ignore the generated warnings\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import skimage.morphology as morph\n",
    "from skimage.measure import label, regionprops\n",
    "import tifffile # tiff file manipulation\n",
    "import os\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line program management\n",
    "\n",
    "Command example : \\\n",
    "python3 segment.py imageToSegment seededImage 6 \\\n",
    "python3 segment.py imageToSegment seededImage 26 \\\n",
    "python3 segment --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "                    prog = \"segment\",\n",
    "                    description = \"test program.\")\n",
    "\n",
    "parser.add_argument(\"image\", help=\"The path to the tiff file to segment.\")\n",
    "parser.add_argument(\"seed\", help=\"The path of the tiff file to use as segmentation seed.\")\n",
    "parser.add_argument(\"adjacency\", help=\"Adjacency of the mask (6 or 26)\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "image_filepath = args.image\n",
    "seed_filepath  = args.seed\n",
    "adjacency = int(args.adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIFF image loading and resolution check\n",
    "\n",
    "Seed and image must have the same resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tifffile.TiffFile(image_filepath) as tif:\n",
    "    image = np.array([page.asarray() for page in tif.pages])\n",
    "\n",
    "with tifffile.TiffFile(seed_filepath) as tif:\n",
    "    seed = np.array([page.asarray() for page in tif.pages])\n",
    "\n",
    "\n",
    "if(image.shape != seed.shape):\n",
    "    print(\"Error : seed resolution does not match with image !\", file=sys.stderr)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization of the image with maxTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (image/256).astype(\"uint8\")\n",
    "seed = (seed/256).astype(\"uint8\")\n",
    "print(\"loaded image has shape :\", image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros_like(image)\n",
    "\n",
    "if (adjacency == 26):\n",
    "    # 26 adjacency implicit graph\n",
    "    mask = [[[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "            [[1, 1, 1], [1, 0, 1], [1, 1, 1]],\n",
    "            [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]\n",
    "else:\n",
    "    # 6 adjacency implicit graph\n",
    "    mask = [[[0, 0, 0], [0, 1, 0], [0, 0, 0]],\n",
    "            [[0, 1, 0], [1, 0, 1], [0, 1, 0]],\n",
    "            [[0, 0, 0], [0, 1, 0], [0, 0, 0]]]\n",
    "\n",
    "neighbours = hg.mask_2_neighbours(mask)\n",
    "graph = hg.get_nd_regular_implicit_graph(image.shape, neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of the maxTree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, altitudes = hg.component_tree_max_tree(graph, image)\n",
    "\n",
    "# compute attributes\n",
    "print(\"Starting max-tree filtering...\")\n",
    "height = hg.attribute_height(tree, altitudes)\n",
    "area = hg.attribute_area(tree)\n",
    "\n",
    "\n",
    "# remove unwanted nodes\n",
    "unwanted_nodes = np.logical_or(height > 100, area < 100)\n",
    "\n",
    "tree, node = hg.simplify_tree(tree, unwanted_nodes)\n",
    "new_altitudes = altitudes[node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = hg.reconstruct_leaf_data(tree, new_altitudes)\n",
    "\n",
    "binary_image = (binary_image - np.min(image) > 0).astype(\"uint8\")*255  # binarize image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on the binary image\n",
    "\n",
    "We get the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = morph.area_closing(binary_image)\n",
    "\n",
    "tifffile.imwrite(\"tmp_binary.tif\", binary_image) # this is our basic maxtree segmentation\n",
    "print(\"Created binary image.\")\n",
    "\n",
    "gradient = binary_image\n",
    "gradient = distance_transform_edt(binary_image) # distance_transform_edt compute the distance-map (each pixel take the value of the distance between it and the nearest black pixel)\n",
    "gradient = 255 - gradient\n",
    "tifffile.imwrite(\"tmp_grad.tif\", gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute watershed\n",
    "\n",
    "Rearrange seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = label(seed > 0, background=0, connectivity=1)     # Pixels of value 0 are considered as background.\n",
    "                                                        # Connectivity=1 implies that the pixels immediatly adjacent are considered\n",
    "regions = regionprops(tmp)          # We get information about the regions in the parameter (ex : centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create centroids image and label it.\\\n",
    "labeled_seeds will contain the value of the centroids of each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_seeds = np.zeros_like(seed)\n",
    "\n",
    "i = 0\n",
    "for region in regions:\n",
    "    i += 1\n",
    "    centroid = np.asarray(region.centroid)\n",
    "    x, y, z = int(centroid[0]), int(centroid[1]), int(centroid[2])\n",
    "    labeled_seeds[x, y, z] = tmp[x, y, z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_graph = graph.as_explicit_graph()      # Turn the graph into an explicit graph to apply watershed\n",
    "\n",
    "edge_weights = hg.weight_graph(explicit_graph, gradient, hg.WeightFunction.mean)        # Compute the weight of the edges of the graph with the gradient.\n",
    "                                                                                        # higher is the gradient, higher is the weight of the edge.\n",
    "                                                                                        # The values of the edge will influence the propagation of the watershed\n",
    "labels = hg.labelisation_seeded_watershed(explicit_graph, edge_weights, labeled_seeds)\n",
    "\n",
    "res = np.where(binary_image, labels, 0)     # We only want the usefull regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the result image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite(\"result.tif\", res)             # Creation of the result image\n",
    "os.system(\"python3 colormap.py result.tif\")     # Use the colormap.py file to color each region and the background in black\n",
    "\n",
    "#os.system(\"gmic colored.tif a z\")\n",
    "\n",
    "exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
