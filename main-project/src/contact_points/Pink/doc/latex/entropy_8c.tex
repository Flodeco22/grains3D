\doxysection{entropy.\+c File Reference}
\label{entropy_8c}\index{entropy.c@{entropy.c}}


computes the Shannon entropy of an image or a region  




\doxysubsection{Detailed Description}
computes the Shannon entropy of an image or a region 

{\bfseries{Usage\+:}} entropy in.\+pgm [mask.\+pgm] out.\+list

{\bfseries{Description\+:}} Calculates the Shannon entropy of {\bfseries{im.\+pgm}} (masked by the binary image {\bfseries{mask.\+pgm}}, if given) and saves it in file {\bfseries{out.\+list}} .

Let H(i), i = 0...B-\/1, denote the histogram of {\bfseries{im.\+pgm}}, where B is the number of bins. Let P(i) be the frequency of the level i in the image, that is, P(i) = H(i)/N, where N is the number of pixels of {\bfseries{im.\+pgm}} . Then, the Shannon entropy of {\bfseries{im.\+pgm}} is defined by\+: E = -\/ SUM P(i) log\+\_\+2 P(i), for all i in \{0...B-\/1\}.

{\bfseries{Types supported\+:}} byte 2d, byte 3d, int32\+\_\+t 2d, int32\+\_\+t 3d, float 2d, float 3d

{\bfseries{Category\+:}} signal

\begin{DoxyAuthor}{Author}
Michel Couprie 
\end{DoxyAuthor}
